---
title: Geography or Gemeinschaft?
subtitle: Disentangling the meaning of "community" through word embeddings
---

```{r}
#| include: false
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction

whatever I have to say to get people to read the actual thing I did.

## Background

concepts and meaning and why meaning matters. [no need to be as overwrought as I am in the prospectus version]

what might community mean?

introduce the question of overlap with identity, or communities *based on* identity characteristics.

here's where I explain word embeddings and why they're an interesting tool to use for this case. tbh from the long prospectus version I like my explanation of word embeddings, so I might as well reuse that.

[embeddings here -- at some point cut off and.]

here's probably where I also explain usenet as a virtual community. explain usenet, and soc.motss specifically. - avery dame-griff, rheingold, nancy baym, that slate article, their archived webpage.

soc.motss ("members of the same sex")

I really do think queer folks are especially predisposed to seek out (queer) community in digital spaces.

## Data and Methods

two things: pretrained model, locally trained model on a corpus of my choosing. compare the two.

**pretrained model** [there's a version of this in the proposal too]: 

> The pretrained GloVe embeddings [@pennington2014glove] I use were originally trained on a full English Wikipedia corpus from 2014 and a newswire corpus called Gigaword 5. A social scientist might prefer a more logically bounded population of text for the training corpus, but the more-is-better logic of training data won out. Generally, however, prior social science researchers have found pretrained embeddings to be reasonably robust, stable, and generalizable [@stoltz_cultural_2020, @rodriguez_word_2020], and I find similarly in supplemental analyses. The preliminary consensus is that these pretrained models are good enough for typical social science uses. @kozlowski_geometry_2019, who use historical embeddings, suggest thinking of the associations encoded in these embeddings as coming from a "literary public" with known and unknown biases compared to the general population. 

[NOTE: I made a mistake! I use the 200-dimension version of the model, not the 300-dimension version.]

I haven't decided how much to split off the methods from the results here, but I can keep tinkering with it. Include in my note-to-committee that the boundaries between background/data&methods/results are fluid. the goal was to get all the pieces into the draft, I'm agnostic about where they go.

The GloVe model's vocabulary is truncated to the 400,000 most prevalent words. Many of these words are quite rare or unusual; I achieve more sensical and interpretable results by subsetting the vocabulary to more common words. In the first section of the results below, I do this by intersecting the vocabulary with a second GloVe model pretrained on a corpus of text drawn from Twitter (for 150396 words in total). 

outline what I do

- local neighborhood
- pca
- average/project

this isn't a purely automatic process, it takes an interpretative step.

talk about orthogonal projection math here.

**local model**

(again I'm being really normal by using pretrained GloVe and local word2vec)

talk about soc.motss

years represented in the data: mainly from early 2000s. Usenet Historical Collection (UHC) from the Internet Archive

That's a peril of using an archive. I'm not going to try to estimate what's missing. I think this is robust enough to characterise the early-2000s time period.


preprocessing (Dame-Griff + scikit-learn). (lots to cite from Nelson on this too.)

key model parameters set at : 

choices are consistent with @nelson_leveraging_2021, @rodriguez_word_2020, other lit.

After preprocessing and model fitting, there are 287,680 documents, 26,958,729 tokens, and 71,617 unique words in the final vocabulary (with the minimum threshold for inclusion set to 5 occurrences). Of that vocabulary, 60,728 words also exist in the GloVe model's vocabulary. The words found only in the soc.motss vocabulary are largely misspellings, concatenations of words, encoding errors, foreign languages (especially Spanish), and colloquialisms (especially gay slang, Usenet slang, and emotive language).

notably, this corpus is larger than all 8(?) trans usenet groups put together, and much larger than conventional Usenet data sets like 20 Newsgroups (which uses a smaller temporal slice from more groups). still on the edge of what we might want for decent model quality, but I think my results show that it's okay for what I'm doing. But don't build a chatbot based on it, I guess.

I use three metrics to compare word embeddings, including the embedding for "community," between this local model and the pretrained GloVe model. The "query rank" correlation measure comes from @rodriguez_word_2020 and does [...]; they take it as a measure of stability and model quality. The remaining two measures come from @hamilton_cultural_2016 and are [two different takes on cosine distance ...] "linguistic drift", "cultural shift". Unlike the first measure, these two require mathematically aligning the embeddings matrices as best as possible, using a matrix alignment method called orthogonal Procrustes [@hamilton_diachronic_2016]. 

Finally, I create a third semantic vector of words related to LGBTQ identity. Unlike the other two semantic dimensions, I choose these keywords by hand based on domain knowledge. The exact words are therefore more ad hoc and less principled, but this is not an atypical approach. To match the other dimensions, I pick 10 words: 'lgbt', 'lgbtq', 'glbt', 'gay', 'lesbian', 'bi', 'bisexual', 'transgender', 'queer', and 'homosexual'. ('Gay' is the most common of these words in the soc.motss corpus, appearing 49,486 times; the rarest is 'lgbtq', appearing only 18 times.) Again, by taking an average the vector becomes more robust to the inclusion or exclusion of any given word. 

[explain why I do this: qualitative intuition + inspection of nearest neighbors]

This is no different from previous studies that use keywords to create vectors for concepts like "power" [@nelson_leveraging_2021] or "social class" [@kozlowski_geometry_2019]. 

Foreshadow all the comparison I do. I'm pretty thorough!

Following @nelson_leveraging_2021, I bootstrap key values by fitting forty new models - 95% ci

Because Usenet posts are relatively short documents, I bootstrap posts with replacement, not individual sentences. 

## Results

### Semantic dimensions from a pretrained model

GloVe

The 10 most similar words to "community "are 'communities', 'organizations', 'society', 'local', 'established', 'area', 'part', 'within', 'public', and 'council'.

Here's a pca for GloVe model:

:::

| Dimension 1      | Dimension 2   | Dimension 3   | Dimension 4    | Dimension 5    | Dimension 6   |
|:-----------------|:--------------|:--------------|:---------------|:---------------|:--------------|
| n't              | cooperation   | research      | teach          | populations    | historical    |
| we               | promote       | management    | kids           | populated      | contemporary  |
| if               | governance    | library       | music          | farming        | political     |
| do               | awareness     | science       | teaching       | areas          | history       |
| get              | stakeholders  | facility      | religion       | sustainable    | founding      |
| could            | initiatives   | university    | contemporary   | infrastructure | influential   |
| what             | sustainable   | provides      | teacher        | vast           | described     |
| know             | understanding | institute     | traditions     | cultures       | cultural      |
| would            | commitment    | facilities    | tradition      | population     | role          |
| really           | implement     | program       | feel           | coastal        | movement      |
| ...              | ...           | ...           | ...            | ...            | ...           |
| baptist          | district      | minorities    | government     | alumni         | families      |
| african-american | county        | refugees      | infrastructure | meeting        | parents       |
| encompasses      | situated      | arab          | aid            | met            | workers       |
| nonprofit        | township      | settlers      | region         | member         | employees     |
| methodist        | nearby        | orthodox      | regional       | joined         | teachers      |
| interfaith       | near          | ethnic        | economic       | university     | volunteers    |
| lgbt             | village       | jews          | summit         | attending      | residents     |
| community-based  | suburb        | muslim        | nations        | invited        | kids          |
| non-profit       | town          | christians    | security       | attend         | homes         |
| not-for-profit   | located       | muslims       | cooperation    | attended       | educate       |

: Top 10 and bottom 10 words for first 6 principal components, out of 1000 nearest neighbors to "community," from pre-trained GloVe model (Wikipedia + Gigaword 5) {#tbl-glove}

:::

clear semantic groupings at either end, even if the interpretation of the dimensions are not as clear-cut as the first two.

Focusing on those first two dimensions:

In the figure, I have highlighted three clusters derived from *k*-means clustering to aid in interpretation (While there's no evidence clustering would have been a better approach than dimensionality reduction, the consistency is additional evidence that the principal components are robust).

![](img/discourse/community_pca1000_kmeans3.png)

zooming in on second dimension

![](img/discourse/gemeinschaft_geography_words.png)

here's how you might do something with that

![](img/discourse/despatializing_community.png)

leave breadcrumbs, can be a measurement tool at the document level too (=> talk about this in the discussion as a bridge to the next chapter!)

### Semantic differences in an LGBTQ Usenet group

After fitting a word2vec model to the soc.motss corpus, I examine the neighborhood of words similar to "community" in this model, in order to determine what _community_ "means" in this context and how it might differ from the more generic and general contexts that produced the GloVe model. In the soc.motss model, the 10 most similar words to "community" include words that are identical or thematically similar to words in the GloVe model ("communities," "organizations," "collectives"), words about queer identities ("glbt", "lgbt", "lgbtq"), as well as words related to religious entities: "keshet," an LGBTQ Jewish organization, and both "metropolitan" and "churches." (The 10th word is "webshots".) The similarity between "metropolitan" and "community" is _not_ a geographic reference, but rather a reference to the Metropolitan Community Church (MCC), an LGBTQ-focused Protestant church.

As with the GloVe model, I then select the embeddings for the 1,000 nearest neighboring words to the word "community," and decompose this subset of embeddings with PCA. To exclude marginal words, I only include words shared between the GloVe and soc.motss vocabularies. (With more -- or fewer -- words overall, the PCA dimensions do not appear to remain consistent. By contrast, the PCA dimensions for the GloVe model neighborhood are more robust to different subsets of the vocabulary.) The first six dimensions, shown in @tbl-motss, are considerably less interpretable than those for the GloVe model. There are some thematic groupings; for instance, dimension 2 ranges from geographic words like 'neighborhood' and 'village' to religious words like 'clergy' and 'congregations'. This dimension comes closest to reproducing the geography-Gemeinschaft continuum of the GloVe model, although the semantic scope of the words at the latter end is much narrower. Many of the extreme words are duplicated across dimensions (e.g., there are similar religion-themed words at the bottom of dimension 3), making it difficult to label them distinctly, and many sets of words are semantically mixed or contain too many rare words or proper nouns to characterize. Qualitatively, this shows that while there is some overlap with the connotations of "community" found in the GloVe model above, the same structure of those meanings cannot be discerned here. Instead, more context-specific themes start to appear.

:::

| Dimension 1      | Dimension 2   | Dimension 3   | Dimension 4   | Dimension 5   | Dimension 6   |
|:-----------------|:--------------|:--------------|:--------------|:--------------|:--------------|
| subgroup         | neighborhood  | wellness      | potpourri     | officials     | croome        |
| deepen           | scoured       | stumbleupon   | ahrens        | centers       | activists     |
| subgroups        | village       | msm           | irminsul      | nonprofit     | activist      |
| disparities      | thrift        | transgender   | troth         | auspices      | transgender   |
| hindered         | metreon       | mobilization  | weintraub     | lockup        | parade        |
| inequalities     | wildflower    | nonprofit     | yahad         | disparities   | quintero      |
| personhood       | mayfair       | disparities   | badb          | epidemic      | lesbian       |
| institutionalize | etobicoke     | outreach      | gitlin        | sectors       | gay           |
| salience         | telmo         | visibility    | pittman       | courtrooms    | auckland      |
| assimilate       | area          | linkedin      | gajic         | pediatric     | staged        |
| ...              | ...           | ...           | ...           | ...           | ...           |
| morristown       | pastors       | communion     | clientele     | gajic         | universal     |
| metropolitan     | clergy        | catholics     | walkable      | glbt          | membership    |
| sholom           | tongzhi       | parishes      | influx        | facilitator   | haifa         |
| alejandro        | laity         | congregations | communities   | chatroom      | stumbleupon   |
| cla              | churches      | unitarian     | bathhouses    | queer         | nypl          |
| bradenton        | advocacy      | church        | affluent      | bisexual      | affiliated    |
| citywide         | soulforce     | congregation  | areas         | transgendered | metropolitan  |
| auckland         | rivalries     | episcopal     | businesses    | newsgroup     | user          |
| rodeph           | congregations | denomination  | populations   | poc           | fellowship    |
| montclair        | interfaith    | presbyterian  | neighborhoods | webshots      | webshots      |

: Top 10 and bottom 10 words for first 6 principal components, out of 1000 nearest neighbors to "community," from soc.motss word2vec model {#tbl-motss}

:::

I next attempt to use quantitative measures to systematically characterize differences between the soc.motss-derived and pretrained GloVe models. By situating the metric values for "community" in comparison to all other words in the vocabulary shared between the two models, I contextualize, in a relative sense, how different "community" is overall between the generic and specific contexts. Simultaneously, this offers a form of evaluation for the general quality of the soc.motss model -- if all word embeddings shift dramatically compared to the GloVe model, we might suspect that the local model has failed to uncover anything that makes sense. For the vocabulary as a whole, the three measures are largely consistent, with moderate-to-high correlations between metrics. However, the metric values for the word embedding for "community" are *not* consistent in the amount of change they indicate:

- @fig-correlation shows the distribution of between-model correlation of within-model cosine similarities for all 60,728 words shared between the GloVe model and the soc.motss model vocabularies. Compared to the correlations that @rodriguez_word_2020 report between a pretrained GloVe model and word2vec models trained on the *Congressional Record* corpus, which range between 0.3-0.5 for randomly selected words and 0.5-0.7 for political concepts, the distribution of correlation values is somewhat lower on the whole, but in the same range. (Rodriguez and Spirling pick out only a handful of words for comparison rather than systematically comparing every word in the vocabulary.) "Community" has a between-model correlation of only 0.151 (95% confidence interval from bootstrapped models: 0.116-0.153). This falls at the low end of this distribution and indicates only a weak association of all cosine similarities across the models.

- @fig-drift shows between-model cosine distances for every word, after aligning the matrix of soc.motss embeddings to the matrix of GloVe embeddings. @hamilton_cultural_2016 claim that these are a global measure of linguistic drift. The cosine distance for "community" is 0.492 (95% confidence interval from bootstrapped models: 0.471-0.560). This is substantially below the average distance of 0.672, implying that by this semantic measure community changes less than the typical word. Subjectively, these distance values seem quite high in general -- in a [previous experiment](https://ccgilroy.com/community-discourse/historical-change.html#self-similarity) using historical word embeddings from @hamilton_diachronic_2016 to replicate the work of @kulkarni_statistically_2015, I found that the word "community" shifts by a distance of only 0.403 from 1900 to 1990. By comparison, the word "gay," which undergoes a strong shift in meaning, changes by a distance of 0.822 over the course of the same century. The GloVe and soc.motss corpora are from similar time periods, so I surmise that these differences arise from distinct linguistic styles -- formal newswire and Wikipedia articles versus less formal social text [@mcculloch_because_2019]. (Different model architectures are another possibility.)

- @fig-shift shows what is in some sense an intermediate measure -- it is also a cosine distance, but of within-model cosine similarities to a given focal word, of the local neighborhood of words around that word. @hamilton_cultural_2016 develop this "cultural shift" measure on the premise that these neighbors are semantically relevant in a way that more distance words (which were included in the first correlation measure) are not.On this metric, "community" shows a slightly above average shift of 0.303 (95% confidence interval from bootstrapped models: 0.177-0.396, median cultural shift for all words = 0.264). The wide bootstrapped interval, however, implies that this is the least stable of all three measures. 

Taken together, these measures show that "community" changes in meaning to some degree between the generic GloVe model and the local soc.motss corpus, but they offer no definitive conclusion on the comparative magnitude of that change.

[could be 3 panels of one figure:]

![Correlation (between the two models) of (within-model) cosine similarities for every word and all other words.](img/discourse/overall_vocab_correlation.png){#fig-correlation width=75%}

![Between-model cosine distances for every word ("linguistic drift", @hamilton_cultural_2016).](img/discourse/overall_vocab_linguistic_drift.png){#fig-drift width=75%}

![Nearest-neighbor distances, k = 25 neighbors ("cultural shift", @hamilton_cultural_2016).](img/discourse/overall_vocab_cultural_shift.png){#fig-shift width=75%}

The next logical question, then, is _how_ does the meaning of community in the context of soc.motss differ from the generic context, and how does it remain similar? Using the semantic dimensions I derived from the GloVe model in the previous section, alongside the additional identity-related dimension I curated based on the soc.motss corpus and model, I investigate what changes and why between the two different embeddings for "community." Because these averaged semantic vectors are intrinsically more likely to be closer to the "community" vector derived from the same model, I re-create each of them from the other model's embedding matrix, and I show both sets for consistency. The soc.motss model matrix is aligned to the GloVe model matrix, as are the 40 bootstrapped models for a 95% confidence interval (although the values from the true corpus are in at one case systematically higher than the bootstrapped values). In total, I make 12 comparisons (3 comparison vectors x 2 source models for those vectors x 2 source models for the "community" vector), shown in @fig-semantic.

This key figure shows how "community" in the context of soc.motss de-emphasizes geography but foregrounds identity instead. At the same time, it retains the Gemeinschaft connotations of community. 

- When the averaged vector of geographic words is derived from the GloVe model, the gap in cosine similarities is the largest among any of the comparisons: the soc.motss embedding for "community" has a cosine similarity with the geography vector of only 0.165 (0.108-0.185), compared to 0.594 for the GloVe "community" embedding. The gap narrows to essentially 0 when the geography vector is re-derived from the same 10 words in the soc.motss model, with a similarity of 0.398 (0.374-0.437) for "community" in soc.motss vs 0.404 for "community" in GloVe -- but the following two semantic dimensions have wider gaps in the opposite direction when constructed in this way. 
- The Gemeinschaft vector in the GloVe model is almost identical to the geography vector in its similarity to the GloVe embedding for "community" (0.586), but its similarity to the soc.motss "community" embedding increases to 0.398 (0.374-0.437) -- still lower, but a narrower gap. Recreated with the same words from the soc.motss vectors, the similarities flip: the similarity to "community" from GloVe is 0.386 (almost the same as the comparable geography vector), but the similarity to soc.motss "community" is now higher, at 0.508 (0.440-0.511). 
- The averaged vector for LGBTQ identity-related words is unambiguously more similar to "community" in soc.motss than in the GloVe model, no matter which model's word vectors are used to derive it. The cosine similarities to the soc.motss "community" embedding are 0.497 (0.429-0.485) when derived from the GloVe model and 0.627 (0.585-0.641) from the soc.motss model (the highest within both sets of comparisons). These compare to similarities of only 0.367 and 0.333 for the GloVe "community" embedding respectively (the lowest in both sets of comparisons).

This approach offers clear, stable rankings and comparisons, showing that "community" in the generic sense is equally similar to both geography and Gemeinschaft, and less so to identity, while "community" as used in soc.motss carries stronger connotations of identity, roughly comparable connotations of Gemeinschaft, and weaker connotations of geography.

[could be 2 panels of one figure:]

![](img/discourse/motss_semantic_similarity_comparison.png){#fig-semantic width=75%}

![](img/discourse/motss_orthogonal_comparison.png){#fig-orthogonal width=75%}

To bring everything together and confirm that result, the final piece involves applying the orthogonal projections from the end of the previous section. These come from the GloVe model alone, and I compare them to the "community" embeddings from both models in @fig-orthogonal. For reference, I also compare the two "community" embeddings themselves in the third row of the figure. As shown above, both orthogonal projections of the GloVe "community" embedding -- away from the Gemeinschaft words and away from the geography words -- retain high cosine similarities to the original vector, 0.810 and 0.804 respectively. This is not the case for the soc.motss "community" embedding, which is markedly less similar to community-without-Gemeinschaft (or, community-as-geography), with a similarity of 0.374 (0294-0.393). By contrast, it remains equally similar to community-without-geography (or, community-as-Gemeinschaft) as it is to the GloVe "community" embedding overall, with similarities of 0.510 (0.451-0.523) and 0.508 (0.440-0.529) respectively. This is a different way of looking at the problem of semantic similarity and semantic change, and it has implications for using GloVe vectors as a measurement tool that I will explore in the next chapter.


## Discussion

Recap

Generic structure of meaning makes sense, but wasn't predictable. Doesn't carry over into a local context. So what? It's useful to be able to systematically demonstrate.

this structure (from GloVe) tells us something about the meaning of the word. it shows, mathematically, how it bundles/links together two sets of connotations. 

The sociological element of community is there in everyday usage. You might call this "groupness" [Brubaker et al] or "corporateness" [White]... people don't, though. They call it "community," or *Gemeinschaft* if you're feeling fancy.

in soc.motss, the meaning of community is not totally alien or unrecognizable (and why would it be?) but definitely distinct.

retains Gemeinschaftliche connotations of social organization and groupness.

incorporates markedly less of the geographic or spatial connotations of community.

substitutes identity-related language


interesting in part because this is a time period where groups like soc.motss were proving that virtual community was possible (and academics were debating this, for some reason [CITE]).

Caveats and limitations: corpus and model quality, always. even more work on stability and viability, etc. that said, I'm pretty convinced by the findings I present here.

Bridge: this is just about words. what about the structural/interactional/relational characteristics that go into them?

possible appendix? considering other approaches for disentangling
