---
title: Geography or Gemeinschaft?
subtitle: Disentangling the meaning of "community" through word embeddings
---

## Introduction

"Community" -- the literal word and the latent concept -- is pervasive in everyday discourse. It appears in extremely varied and distinct contexts, everywhere from corporate mission statements to protest slogans. It's as likely to show up on neighborhood murals and graffiti as it is to star in PR materials from local banks and apartment complexes. What is it about the meaning of community that makes it so amenable to these varied uses? What might it be doing when it does appear?

One way to approach the meaning of "community" is by examining how the concept shows up in everyday social contexts. This chapter adopts innovations from natural language processing from the past decade to learn about community from how the word is used in naturally-occurring language. My approach is to systematically investigate connotations of community across text using word embeddings [@mikolov_efficient_2013] -- a type of model that mathematically represent words based on the contexts in which they appear. The most basic mathematical model of word meanings is an overlay of many different contexts; with some adjustments, however, word embedding models can compare different sets of contexts instead. Here, I compare a generic model trained by researchers with access to very large corpora of texts to a local and specific model that I fit to a corpus of posts from an LGBTQ virtual community. 

The foundation this analysis provides offers a bridge toward investigating two interrelated fundamental questions: first, what is going on when people literally talk about "community"; and second, what is happening when people invoke the latent social concept that the word "community" points to, whether they literally use that word or not. This effort responds, in part, to a call from @levine_paradox_2017 to investigate the power and ambiguity of "community" in contexts other than his own, where he shows how it operates as a rationale in the case of local governance; it also responds to a host of LGBTQ research that sometimes problematizes community [@orne_boystown_2017; @winer_solidarity_2022] and sometimes takes it for granted [@frost_measuring_2012]. I'm especially interested in how the empirical everyday meaning(s?) of "community" might correspond to or deviate from sociological understandings of _Gemeinschaft_, of community as a meso-level form of social organization [@tonnies_community_2001; @brint_gemeinschaft_2001]. I show that "community" in the generic sense brings together two semantic domains; in a queer context one of those connotations recedes to the background and a third domain emerges to take precedence -- community-as-Gemeinschaft turns out to be the common bridge between the two.

The computational method of word embeddings offers an empirical technique that is uniquely suited for investigating these questions, because -- unlike other methods for computational text analysis -- they move from surface-level words to underlying meanings and their relations [@stoltz_cultural_2021; @arseniev-koehler_machine_2022]. While the aim of this project is descriptive and intrinsic, to provide a grounded account of the everyday social life of a social concept, it also potentially furnishes a more precise tool for measuring when social actors implicitly or explicitly invoke community and belonging -- in the Gemeinschaft sense -- in the course of discursive action and interaction.

I first undertake a "close read" of the embedding for "community" in a generic set of word embeddings, to understand what "community" means in contemporary English-language discourse. Then, I apply algebraic transformations to show how the spatial and sociological connotations of the word can be disentangled. In the second half of the analysis, I fit a local word embedding model to informal written text drawn from an LGBTQ Usenet newsgroup [@dame-griff_herding_2019]. I compare how the concept of community is used in this group to the generic model. 

This application is appealing for a few reasons. First, informal written text [@mcculloch_because_2019] is the most logical source for analyzing linguistic expressions of community, because it directly shows how the meaning of community is constructed through specifically social interactions. Because Usenet is an older set of virtual communities, originating in the 1980s and declining in the early 2000s, social interactions in Usenet groups were text-based, as opposed to increasingly the image-, sound-, and video-centric content of contemporary social media. Spoken language is more ephemeral and harder to collect and analyze computationally; more formal written texts like news articles -- including the source text for the generic model I compare [@pennington2014glove] -- are further afield from the actual experience of community. Second, while no longer widely-used, Usenet groups are one of the earliest instances of the successful creation of vibrant virtual communities -- and in fact, their existence offered critical evidence demonstrating that virtual community is possible at all [@rheingold_virtual_2000]. Because the preceding and following chapters draw on more contemporary cases, this historical perspective sets up a more generalizable foundation for the dissertation as a whole. 

## Background

### "Community" and the meanings of concepts

Community has a power and ambiguity that render it suitable for strategic rhetorical uses in everyday discourse. Two qualitative examples illustrate the shades of meaning that "community" can take on; together, these illustrate the range of variation that I might expect to see in a computational investigation of what community means as a folk concept. First, in the context of local governance, @levine_paradox_2017 observes that "community" becomes a "floating signifier of the good," a halo of positivity to cover the real operation of local decision-making and to provide legitimacy for action. For Levine, this is harmful; he notes the impossibility of "the community" wanting one single thing as a uniform entity, and the harms of ascribing collective representational authority to whoever can show up to participatory events [@levine_constructing_2021]. In his case, the word is constantly used in a positive and justificatory light, but so flexibly as to lose coherent meaning. Second, and in contrast to that wholehearted positivity, @winer_solidarity_2022 finds that his interviewees have an ambivalent and distancing relationship with the "imagined gay community," drawing a distinction between "the community" at large and their own social circles. Rather than pure vagueness, this points to another specific rhetorical use, to critique an in-group's flaws rather than to justify desired actions. In these accounts, "community" assumes differing valences, with slippery or counterintuitive referents, but in each case the concept does important discursive work. I do not aim to create a taxonomy of these rhetorical strategies; instead I'll show how all of these uses together add up and contribute to the overall semantic resonance that "community" takes on. Language, after all, is social and shared [@saussure_cours_1972]; later I'll show how that shared foundation can be a springboard for understanding local deviations.

For fully understanding the social life of a complex concept, academic definitions are insufficient on their own, but worth reviewing as an anchor for comparison. "Community" is a phenomenon sociologists have elaborated on since @tonnies_community_2001; they've created taxonomies of different types of communities [@brint_gemeinschaft_2001]; argued over what communities count as "real" [@driskell_are_2002; @rheingold_virtual_2000]; and debated about what features -- shared social networks/interactions or shared cultural/moral traits -- are most fundamental to the creation and experience of it [@vaisey_structure_2007; @boessen_networks_2014]. What emerges consistently is the metaphor of a tightly knit social fabric, a group of people bound together by shared ties, shared culture, and possibly shared place. 

However, the issue with using academic definitions of "community" as a starting point is that a strict definitional logic of concepts and categories does not apply "out there" in the real social world; classical logic may be useful for technical jargon, but it is not how ordinary human concepts work. Instead, everyday concepts are fuzzy and prototype-based [@rosch_family_1975; @lakoff_women_2008; @lakoff_women_2008; @bowker_sorting_2000; @zerubavel_fine_2002; @monk_inequality_2022]. One way to see this is to think about how people figure out that something _is_ a community in the first place. As @bruckman_should_2022 argues, we might decide that a virtual community like Wikipedia is a community through mental comparison to prototypes of community like a small town. A given example of community does not have to have all of a specific set of features in order to fall under the concept; rather, concepts and categories are bundles of "intensions," inherently fuzzy constellations of characteristics and cues. "Community," as an everyday concept, bundles together a spread of connotations; as I will show, the most notable of these are a geographic sense of "local place" and a sociological sense of "social group" or "object of belonging." Because "community" encompasses both, even the most mundane use of community to refer to local place might still invoke the sentiment and connotation of *Gemeinschaft*. That is partly where the fuzziness and ambiguity of community as a concept could come from, and also part of the concept's discursive power. However, distinguishing these two senses is necessary in order to open up a window into where and how the underlying meaning of *Gemeinschaft* and belonging appears in different discursive contexts.

Finally, I'll introduce the question of the potential overlap between community and identity. Communities can be based on shared social identity characteristics [@brint_gemeinschaft_2001]. In the context of the cultural sociology of markedness, @zerubavel_taken_2018 notes that this isn't necessarily true for unmarked identity categories: "the heterosexual community" is an empty, nonsensical statement, while "the LGBTQ community" is a common and sensical one.

### Using word embeddings to measure meaning

This project, then, uses an empirical, inductive, and computational approach to discover what community means and compare it to theoretical expectations derived from sociological literature. It integrates the sociological definition of Gemeinschaft in an iterative way, making this an abductive approach [@brandt_abductive_2021], rather than a purely grounded one [@nelson_computational_2017]. To examine the resonances and connotations of community in generic English discourse, word embeddings are my computational method of choice. Word embeddings are a relatively recent [@mikolov_efficient_2013] computational operationalization of an old linguistic idea, called the _distributional hypothesis_ [@sahlgren_distributional_2008]. As @firth_synopsis_1957 put it, "You shall know a word by the company it keeps." Accordingly, these models represent words as a function of all of their immediate contexts. To give one example: 

> "The history of all hitherto existing **society** is the history of class struggles." [@marx_communist_1972]

An embeddings model would take this sentence and learn about the semantic connotations of the the word "society" from its position near "history", "class", and "struggle"; it might also learn linguistic features common to nouns from its position in relation to words like "is" and "of." Naturally, a model needs many such examples as training data, to produce a single overarching numeric representation for each word in a vocabulary. There are two main commonly-used word embeddings models -- word2vec, based on a shallow neural network [@mikolov_efficient_2013], and GloVe, based on cooccurrence matrix factorization [@pennington2014glove]. (The differences are minor, so I choose one or the other based on convenience, not principle.) There are many other innovations and variations on the basic method; the most interesting is a family of models called _contextualized_ word embeddings (e.g. BERT), which allow for more than one vector per word, instead of a single one -- of course, these models take much more training data, and are much more complex! Simpler, older models offer a more straightforward and interpretable starting point; tackling the question of what "community" means in everyday English, in practice.

A generic model with a robust, comprehensive view of as many contexts as possible would approximate "the" meaning of every word in a language. To train general models for a given language, the most common corpora are large and publicly accessible texts from the Internet, e.g., Wikipedia pages, newswire articles, social media, or anything else that can be conveniently crawled from the web. (Historical embeddings use digitized book corpora.) These pretrained models can be used for a variety of questions and tasks, but they stand in contrast to locally trained models derived from specific corpora. Of course, meanings of words do vary -- over time, over space, and by other social characteristics [@bamman_distributed_2014; @soni_abolitionist_2021]. A general model trained on easily-accessible data works to the extent that meanings are common or shared; of course, this flattens variation. Given the social characteristics of the authors of formal online texts like Wikipedia or news corpora, in terms of gender, race, education, nationality, etc. [@hargittai_mind_2015; @vrana_16_2020], models trained on those data necessarily overrepresent hegemonic cultural viewpoints. This overrepresentation is a form of bias, but also a matter of substantive interest [@caliskan_semantics_2017; @garg_word_2017; @jones_stereotypical_2020]. 

Distinct from other text-as-data methods (e.g. keyword dictionaries or topic models), embeddings models create dense, distributed vector representations of words. In this way, word embeddings encode a relational model of meaning; they build up a system of signs [@saussure_cours_1972], a vocabulary, in which distances (or their inverse, _similarity_ measures) in a high-dimensional space can be calculated between every pair of words. This makes embeddings useful for social-science problems where meaning matters -- especially where variations or changes in meaning are of interest; they've been applied fruitfully in cultural sociology [@kozlowski_geometry_2019] and political science [@rheault_word_2020]. An embeddings model can be thought of as distilling shared, declarative public culture [@lizardo_improving_2017]; @arseniev-koehler_machine_2022 go even further to argue that the training process is a reasonable heuristic model for actual cultural cognition.

But the dimensions the models learn are not themselves interpretable (nor are they consistent across models, meaning that different embedding matrices must be aligned for comparison). To derive interpretable dimensions, social scientists use anchor words and simple algebra. One common approach is to construct new binary dimensions through subtraction [@kozlowski_geometry_2019; @taylor_integrating_2020], opposing pairs of concepts that can be thought of as antonyms (e.g. rich - poor, woman - man). This idea springs from the algebraic analogy tasks that first made word embeddings notable in NLP (e.g., king - man + woman $\approx$ queen). While these binary oppositions have a clear basis in cultural sociology [@durkheim_elementary_2001; @saussure_cours_1972; @douglas_purity_1966], they are not the only possibility. They don't necessarily make sense for a concept that might bundle together multiple overlapping connotations or characteristics.

Instead, in this work, I deviate and borrow a different algebraic idea from NLP: "de-biasing" an embedding through orthogonal projection away from a target word vector [@gonen_lipstick_2019]. This approach originates in an attempt to mitigate gender bias in the words for different professions and occupations -- which is undesirable for NLP tasks such as machine translation [@caliskan_semantics_2017], even if it represents cultural associations or demographic facts about particular occupations that might be worth studying in themselves [@jones_stereotypical_2020]. That foundational work on this method makes it clear that it does not remove all the connotations of the undesired word -- i.e., it does not fully succeed in de-biasing -- but it is successful enough to use to disentangle the connotations of a concept like community. 

### An early LGBTQ virtual community: the soc.motss Usenet newsgroup: 

My case study is an early virtual community, an LGBTQ Usenet group called soc.motss.Usenet is a distributed system for sharing electronic messages which predates the contemporary Internet [@rheingold_virtual_2000], organized into topical groups such as alt.atheism or rec.motorcycles (to take two examples from the "20 Newsgroups" dataset [@Lang95]). Some of these groups are reported to have had a strong sense of community, while others were known for their hostility [@baym_practice_1994; @dame-griff_herding_2019]. Usenet is of interest because the time period of its heyday is when people were demonstrating that virtual community was, in fact, possible [@driskell_are_2002; @rheingold_virtual_2000; @hampton_neighboring_2003; @calhoun_community_1998]. Moreover, as @boyd_its_2014 points out, even if particular platforms are passé, the social processes that unfold on them are not. Usenet groups are well-suited for studying the creation of community using computational text analysis methods because they are both conversation-oriented and text-based; these kinds of virtual interactions can have similar feedback effects to those associated with face-to-face interaction rituals [@dimaggio_interaction_2018].

LGBTQ people may be especially predisposed to seek out (queer) community in digital spaces. The internet has long been recognized for its potential for marginalized groups [@mehra_internet_2004; @boyd_what_2015], with LGBTQ people using virtual communities for connection and support that may be lacking in offline social spaces [@dym_coming_2019]. LGBTQ groups and interests have been present and visible since the earliest virtual spaces [@rheingold_virtual_2000; @auerbach_first_2014], and LGBTQ people have continued to play a key role as early adopters of new technologies for digital social life (e.g., mobile and location-based platforms [@orne_boystown_2017]) through to the present day.

Soc.motss -- where "motss" stands for "members of the same sex" -- was oldest and largest LGBTQ Usenet group. According to a history recounted by @auerbach_first_2014 in *Slate*, it was founded in 1983 (as net.motss), not long after Usenet came into existence in 1980. In terms of case selection, soc.motss is worth studying not because it is typical or representative, but because it is unique and historically important. As "the first gay space on the Internet" [@auerbach_first_2014], it influenced the many queer spaces that would come after it; as one of the largest spaces of its time period, it provides a sufficient corpus for modeling with word embeddings.

An [archived version](https://web.archive.org/web/20010629135057/http://www.soc-motss.org/doc/faq/faq_participants.html) of the soc.motss FAQ from 2001 describes the group as follows (in a section headed 'Our "we"'):

> Soc.motss serves non-heterosexual Internet communities. To signal inclusiveness, we use the acronym LGBTO, for Lesbian, Gay, Bisexual, Transgendered and Others, "others" meaning supportive straight people. The newsgroup is a predominantly non-heterocentric space where we can discuss issues of importance to our communities.

Elsewhere, the FAQ provides ample evidence that this *is* a cohesive group and a virtual community by any definition of the term. It has norms for participation, a group discursive style [@eliasoph_culture_2003], and community-building events like in-person meetups ("motss.con") [@auerbach_first_2014; @rheingold_virtual_2000]. Of course, there were other LGBTQ newsgroups, such as soc.support.youth.gay-lesbian-bi or the several trans Usenet groups @dame-griff_herding_2019 has already studied. These might be worth analyzing on their own terms or comparing, but it doesn't make sense to mash a bunch of possibly distinct group cultures and discursive styles together in one corpus. Soc.motss offers a well-defined, prototypical early LGBTQ virtual space.

## Data and Methods

I analyze the meaning of "community" through mathematical measures of similarity in the contexts of two word embedding models -- a generic pretrained GloVe model, and a word2vec model that I train locally on the Usenet soc.motss corpus -- and then I compare the two.

### Pretrained model (GloVe, Wikipedia + newswire text)

The pretrained GloVe embeddings [@pennington2014glove] I use were originally trained on a full English Wikipedia corpus from 2014 and a newswire corpus called Gigaword 5. A social scientist might prefer a more logically bounded population of text for the training corpus, but the more-is-better logic of training data won out. Generally, however, prior social science researchers have found pretrained embeddings to be reasonably robust, stable, and generalizable [@stoltz_cultural_2020; @rodriguez_word_2020], and I find similarly in supplemental analyses. The preliminary consensus is that these pretrained models are good enough for typical social science uses. @kozlowski_geometry_2019, who use historical embeddings, suggest thinking of the associations encoded in these embeddings as coming from a "literary public" with known and unknown biases compared to the general population. 

The GloVe model's vocabulary is truncated to the 400,000 most prevalent words. Many of these words are quite rare or unusual; I achieve more sensical and interpretable results by subsetting the vocabulary to more common words. In the first section of the results below, I do this by intersecting the vocabulary with a second GloVe model pretrained on a corpus of text drawn from Twitter (for 150,396 words in total). 

To interrogate what potential meanings for the focal concept of "community" are encoded in this generic model, I take the following steps. 

1. I decompose the local neighborhood, measured using cosine similarity, of words similar to the focal word (N = 1000) through principal components analysis (PCA). 
2. I inspect the resulting PCA dimensions for the proportion of local variation they explain and for any potential substantive interpretation. Here, even though the embeddings in the neighborhood of "community" do not fall into discrete clusters, I cluster them with K-means to aid in interpretation.
3. I average the vectors for extreme words (N = 10) along a PCA axis of substantive interest to "debias" [@gonen_lipstick_2019] the focal word vector through orthogonal projection.

This isn't a purely automatic process, but rather necessarily an interpretive one, so it would take a similar amount of interpretation to extend this method to other complex social-scientific concepts that appear in everyday discourse.

### Local corpus and model (soc.motss, word2vec)

I build my local corpus and model as follows. I download a set of posts from the soc.motss newsgroup archived in the Usenet Historical Collection (UHC), hosted by the Internet Archive. This archive contains nearly 300,000 posts spanning the years 1999-2013, with a peak in the early 2000s and a continual decline in post volume thereafter (shown in @fig-posts). According to @dame-griff_archiving_2017, there were no systematic attempts to archive Usenet before 1995. While I investigate other potential archival sources, the UHC archive is so much larger that I do not attempt to merge sources together. (The second available archive, from Google Groups, is spotty; it has only 1,074 posts from net.motss, the first iteration of the group, for 1983-1986. The Google Groups soc.motss archive contains only 60,400 posts from 1986-2022 (though the most recent posts are entirely spam), with only 9,847 posts from before 1999-04-17, when the UHC archive begins.) Archives inherently risk being incomplete, but I believe this corpus is robust enough to characterise the culture and language of the group in the early-2000s time period.

![Posts from soc.motss archived in the Usenet Historical Collection by year.](img/discourse/motss_posts_by_year.png){#fig-posts width=75%}

I load and preprocess the soc.motss UHC archive using Dame-Griff's [Python scripts](https://github.com/apdame/usenet-tools), developed for analyzing transgender Usenet groups, strip quotes and footers from the text with scikit-learn [@scikit-learn] tools intended for the 20 Newsgroups dataset, and lowercase and tokenize the text with the gensim package [@rehurek_lrec]. This preprocessing is relatively minimal, but I note that any computational text analysis can be sensitive to preprocessing choices [@denny_assessing_2016; @nelson_computational_2017].

I fit a word2vec model to the processed corpus using gensim [@rehurek_lrec]. Key word2vec model parameters are set at a vector size of 200, a context window of 6, and a minimum word occurrence threshold of 5. I use skip-gram with negative sampling as the model architecture and train for 10 epochs. The parameter choices I make are consistent with @nelson_leveraging_2021, @rodriguez_word_2020, and other social science research using word2vec models. Following @nelson_leveraging_2021, I also bootstrap key estimates by fitting forty new models to create a 95% confidence interval. Because Usenet posts are relatively short documents, I bootstrap posts with replacement, not individual sentences.

After preprocessing and model fitting, there are 287,680 documents, 26,958,729 tokens, and 71,617 unique words in the final vocabulary (with the aforementioned minimum threshold for inclusion set to 5 occurrences). Of that vocabulary, 60,728 words also exist in the GloVe model's vocabulary. The words found only in the soc.motss vocabulary are largely misspellings, concatenations of words, encoding errors, foreign languages (especially Spanish), and colloquialisms (especially gay slang, Usenet slang, and emotive language).

Notably, this corpus is larger than all six trans usenet groups that @dame-griff_herding_2019 has archived put together, and much larger than conventional Usenet data sets like 20 Newsgroups [@Lang95] (which uses a smaller temporal slice from more groups). It is still on the lower bound of what might be desirable for model qualtiy, but I believe my results below show that it is robust enough for broad, high-level findings. (Just don't build a chatbot based on it, I guess.)

I use three metrics to compare word embeddings, including the embedding for "community," between this local model and the pretrained GloVe model. The "query rank" correlation measure comes from @rodriguez_word_2020 and is the Pearson correlation between models of within-model cosine similarities for a word and every other word in the vocabulary; they take this metric as a measure of stability and model quality. The remaining two measures come from @hamilton_cultural_2016 and are two different applications of cosine distances (= 1 - cosine similarity). Their "linguistic drift" measure compares the cosine distance of the same word directly across models; their "cultural shift" measure is a second-order comparison using the cosine distance of the cosine similarities of the nearest neighbors to the word. Unlike the first measure, these two require mathematically aligning the embeddings matrices as best as possible, using a matrix alignment method called orthogonal Procrustes [@hamilton_diachronic_2016]. 

Finally, to complement the semantic dimensions derived from the PCA decomposition of the GloVe model, I create a third semantic vector of words related to LGBTQ identity. Unlike the other two semantic dimensions, I choose these keywords by hand based on domain knowledge and manual inspection of nearest neighbors. The exact words are therefore more ad hoc and less principled, but this is not an atypical approach; it is no different from previous studies that use keywords to create vectors for concepts like "power" [@nelson_leveraging_2021] or "social class" [@kozlowski_geometry_2019]. To match the other dimensions, I pick 10 words: 'lgbt', 'lgbtq', 'glbt', 'gay', 'lesbian', 'bi', 'bisexual', 'transgender', 'queer', and 'homosexual'. ('Gay' is the most common of these words in the soc.motss corpus, appearing 49,486 times; the rarest is 'lgbtq', appearing only 18 times.) Again, by taking an average the vector becomes more robust to the inclusion or exclusion of any given word. 

## Results

### Semantic dimensions of "community" from a pretrained model

I proceed from a standard set of word embeddings pre-trained on Wikipedia and newswire text (i.e., formal, written online English) and publicly released [@pennington2014glove]. This is a generic set of embeddings, with all of the cultural biases that that necessarily entails. Word embeddings encode a notion of similarity; a key way to understand what a given word means in a model is to examine the words that are most closely related to it. These are the words that would show up in similar contexts. The 10 most similar words to "community" in the GloVe model are 'communities', 'organizations', 'society', 'local', 'established', 'area', 'part', 'within', 'public', and 'council'; both spatial and social dimensions are evident.

For a more robust picture of what community means, I expand my view and select the 1000 words that are the nearest neighbors to it in the vocabulary, as measured by cosine similarity. I then decompose that subset of the embeddings space using principal components analysis, which I choose for its relative interpretability compared to other dimensionality reduction methods. @tbl-glove shows the ends of the first six PCA dimensions from the nearest neighbors to "community" in the GloVe model. Each set of 10 words qualitatively shows a reasonable amount of semantic coherence, and in some cases the opposition of each end of a given dimension is also interpretable. Note that the 200 dimensions of the embeddings space encode a substantial amount of subtle information that is lost with dimensionality reduction, so the proportion of variance explained by the first several dimensions is relatively low. (@kozlowski_geometry_2019 have shown similar results in an experiment with PCA and with explicit cultural dimensions, so this is unsurprising.)

| Dimension 1      | Dimension 2   | Dimension 3   | Dimension 4    | Dimension 5    | Dimension 6   |
|:-----------------|:--------------|:--------------|:---------------|:---------------|:--------------|
| n't              | cooperation   | research      | teach          | populations    | historical    |
| we               | promote       | management    | kids           | populated      | contemporary  |
| if               | governance    | library       | music          | farming        | political     |
| do               | awareness     | science       | teaching       | areas          | history       |
| get              | stakeholders  | facility      | religion       | sustainable    | founding      |
| could            | initiatives   | university    | contemporary   | infrastructure | influential   |
| what             | sustainable   | provides      | teacher        | vast           | described     |
| know             | understanding | institute     | traditions     | cultures       | cultural      |
| would            | commitment    | facilities    | tradition      | population     | role          |
| really           | implement     | program       | feel           | coastal        | movement      |
| ...              | ...           | ...           | ...            | ...            | ...           |
| baptist          | district      | minorities    | government     | alumni         | families      |
| african-american | county        | refugees      | infrastructure | meeting        | parents       |
| encompasses      | situated      | arab          | aid            | met            | workers       |
| nonprofit        | township      | settlers      | region         | member         | employees     |
| methodist        | nearby        | orthodox      | regional       | joined         | teachers      |
| interfaith       | near          | ethnic        | economic       | university     | volunteers    |
| lgbt             | village       | jews          | summit         | attending      | residents     |
| community-based  | suburb        | muslim        | nations        | invited        | kids          |
| non-profit       | town          | christians    | security       | attend         | homes         |
| not-for-profit   | located       | muslims       | cooperation    | attended       | educate       |

: Top 10 and bottom 10 words for first 6 principal components, out of 1000 nearest neighbors to "community," from pre-trained GloVe model (Wikipedia + Gigaword 5) {#tbl-glove}

@fig-pca focuses on the first two dimensions, effectively projecting the 200-dimensional vectors down into two-dimensional space. The first dimension (the x-axis in Figure 1) ranges from words like "if" and "we" and "not" to words like "not-for-profit," "community-based," "lgbt," and "interfaith." Based on the distributions of words along these dimensions, I label this first dimension as encoding a linguistic distinction between common, functional words and words that are more complex and substantive. While important for structuring the overall space of meaning, this distinction is not relevant for my analysis (except potentially as a filtering mechanism). The second dimension (the y-axis in Figure 1), however, is more salient. Ranging from words like "town" and "located" to words like "cooperation," "governance," "organizations," and "collective," it encodes what I label a distinction between geography and Gemeinschaft. "Community" itself falls nearly in the middle between the two poles of this dimension. In the figure, I have highlighted three clusters derived from *k*-means clustering to aid in interpretation. The first cluster captures the functional linguistic words on dimension 1, which are not differentiated much on dimension 2; the second and third clusters separate out the more substantive words on dimension 1 into two semantic groupings: geography words on the high end of dimension 2 and Gemeinschaft words on the lower end. While there's no evidence clustering would have been a better approach than dimensionality reduction, the consistency is additional evidence that the principal components are robust.

![PCA decomposition of 1000 nearest word embeddings to "community", showing the first two dimensions. While the space is continuous, k-means clustering with k = 3 effectively divides it into functional words in green, geography words in blue, and Gemeinschaft words in red.](img/discourse/community_pca1000_kmeans3.png){#fig-pca width=75%}

Based on that interpretation, I select the second dimension for further analysis as representing a contrast between spatial and sociological connotations. Drawing on each end of this geography-Gemeinschaft continuum, I select the 10 words (from the 1000-word neighborhood) that are the most extreme on either end. @fig-dim-2 displays these two sets of words again and shows that they do in fact fall into two distinct blocks -- highly similar within each group, and highly distinct from the other group. By construction, the word "community" is highly similar to both groups -- it quite literally bundles these two connotations together in a single concept. To produce a more robust vector measure for each underlying connotation of "geography" and "Gemeinschaft," I average the 10 individual word vectors, as is common practice [@kozlowski_geometry_2019; @waller_quantifying_2021]. 

![Similarities of the 10 highest and 10 lowest words along PCA dimension 2, which I have labeled geography -- Gemeinschaft.](img/discourse/gemeinschaft_geography_words.png){#fig-dim-2 width=75%}

Finally, I project the vector for "community" away from the averaged geography vector (and, implicitly, toward the Gemeinschaft end of the continuum). In effect, this "de-biases" [@gonen_lipstick_2019] the new "community" vector of those connotations, creating a new concept vector I label community-without-geography -- or, alternatively, community-as-Gemeinschaft. @fig-proj is a two-dimensional projection of this process that illustrates the results. In the figure, the x-axis represents similarity to the new community-as-Gemeinschaft vector; the y-axis represents similarity to the averaged geography words. By definition, each vector has a similarity to itself of 1, and the result of orthogonal projection is that the community-as-Gemeinschaft vector has a similarity to the geography vector of exactly 0. This has two consequences: community-as-Gemeinschaft remains very similar to the original community vector _and_ to the averaged Gemeinschaft vector. An alternative approach -- subtracting out the geography domain -- does not result in a vector with the same properties. I argue that the projection approach produces an embedding that means community in a purely sociological sense, rather than a spatial one. This provides a comparative tool for analyzing the meaning of community in the context of a different corpus in the next section, as well as a more general measurement tool in ways that I will outline in the discussion.

![Orthogonal projection of the embedding for "community" away from the averaged vector of 10 geography-related words. The resultant embedding (community | geography) is highly similar to the averaged vector of 10 Gemeinschaft words. A binary opposition (community - geography) is shown for comparison, but is less similar to the Gemeinschaft words.](img/discourse/despatializing_community.png){#fig-proj width=95%}

### Semantic differences in an LGBTQ Usenet group

After fitting a word2vec model to the soc.motss corpus, I examine the neighborhood of words similar to "community" in this model, in order to determine what _community_ "means" in this context and how it might differ from the more generic and general contexts that produced the GloVe model. In the soc.motss model, the 10 most similar words to "community" include words that are identical or thematically similar to words in the GloVe model ("communities," "organizations," "collectives"), words about queer identities ("glbt", "lgbt", "lgbtq"), as well as words related to religious entities: "keshet," an LGBTQ Jewish organization, and both "metropolitan" and "churches." (The 10th word is "webshots".) The similarity between "metropolitan" and "community" is _not_ a geographic reference, but rather a reference to the Metropolitan Community Church (MCC), an LGBTQ-focused Protestant church.

As with the GloVe model, I then select the embeddings for the 1,000 nearest neighboring words to the word "community," and decompose this subset of embeddings with PCA. To exclude marginal words, I only include words shared between the GloVe and soc.motss vocabularies. (With more -- or fewer -- words overall, the PCA dimensions do not appear to remain consistent. By contrast, the PCA dimensions for the GloVe model neighborhood are more robust to different subsets of the vocabulary.) The first six dimensions, shown in @tbl-motss, are considerably less interpretable than those for the GloVe model. There are some thematic groupings; for instance, dimension 2 ranges from geographic words like 'neighborhood' and 'village' to religious words like 'clergy' and 'congregations'. This dimension comes closest to reproducing the geography-Gemeinschaft continuum of the GloVe model, although the semantic scope of the words at the latter end is much narrower. Many of the extreme words are duplicated across dimensions (e.g., there are similar religion-themed words at the bottom of dimension 3), making it difficult to label them distinctly, and many sets of words are semantically mixed or contain too many rare words or proper nouns to characterize. Qualitatively, this shows that while there is some overlap with the connotations of "community" found in the GloVe model above, the same structure of those meanings cannot be discerned here. Instead, more context-specific themes start to appear.

| Dimension 1      | Dimension 2   | Dimension 3   | Dimension 4   | Dimension 5   | Dimension 6   |
|:-----------------|:--------------|:--------------|:--------------|:--------------|:--------------|
| subgroup         | neighborhood  | wellness      | potpourri     | officials     | croome        |
| deepen           | scoured       | stumbleupon   | ahrens        | centers       | activists     |
| subgroups        | village       | msm           | irminsul      | nonprofit     | activist      |
| disparities      | thrift        | transgender   | troth         | auspices      | transgender   |
| hindered         | metreon       | mobilization  | weintraub     | lockup        | parade        |
| inequalities     | wildflower    | nonprofit     | yahad         | disparities   | quintero      |
| personhood       | mayfair       | disparities   | badb          | epidemic      | lesbian       |
| institutionalize | etobicoke     | outreach      | gitlin        | sectors       | gay           |
| salience         | telmo         | visibility    | pittman       | courtrooms    | auckland      |
| assimilate       | area          | linkedin      | gajic         | pediatric     | staged        |
| ...              | ...           | ...           | ...           | ...           | ...           |
| morristown       | pastors       | communion     | clientele     | gajic         | universal     |
| metropolitan     | clergy        | catholics     | walkable      | glbt          | membership    |
| sholom           | tongzhi       | parishes      | influx        | facilitator   | haifa         |
| alejandro        | laity         | congregations | communities   | chatroom      | stumbleupon   |
| cla              | churches      | unitarian     | bathhouses    | queer         | nypl          |
| bradenton        | advocacy      | church        | affluent      | bisexual      | affiliated    |
| citywide         | soulforce     | congregation  | areas         | transgendered | metropolitan  |
| auckland         | rivalries     | episcopal     | businesses    | newsgroup     | user          |
| rodeph           | congregations | denomination  | populations   | poc           | fellowship    |
| montclair        | interfaith    | presbyterian  | neighborhoods | webshots      | webshots      |

: Top 10 and bottom 10 words for first 6 principal components, out of 1000 nearest neighbors to "community," from soc.motss word2vec model {#tbl-motss}

I next attempt to use quantitative measures to systematically characterize differences between the soc.motss-derived and pretrained GloVe models. By situating the metric values for "community" in comparison to all other words in the vocabulary shared between the two models, I contextualize, in a relative sense, how different "community" is overall between the generic and specific contexts. Simultaneously, this offers a form of evaluation for the general quality of the soc.motss model -- if all word embeddings shift dramatically compared to the GloVe model, we might suspect that the local model has failed to uncover anything that makes sense. For the vocabulary as a whole, the three measures are largely consistent, with moderate-to-high correlations between metrics. However, the metric values for the word embedding for "community" are *not* consistent in the amount of change they indicate:

- @fig-correlation shows the distribution of between-model correlation of within-model cosine similarities for all 60,728 words shared between the GloVe model and the soc.motss model vocabularies. Compared to the correlations that @rodriguez_word_2020 report between a pretrained GloVe model and word2vec models trained on the *Congressional Record* corpus, which range between 0.3-0.5 for randomly selected words and 0.5-0.7 for political concepts, the distribution of correlation values is somewhat lower on the whole, but in the same range. (Rodriguez and Spirling pick out only a handful of words for comparison rather than systematically comparing every word in the vocabulary.) "Community" has a between-model correlation of only 0.151 (95% confidence interval from bootstrapped models: 0.116-0.153). This falls at the low end of this distribution and indicates only a weak association of all cosine similarities across the models.

- @fig-drift shows between-model cosine distances for every word, after aligning the matrix of soc.motss embeddings to the matrix of GloVe embeddings. @hamilton_cultural_2016 claim that these are a global measure of linguistic drift. The cosine distance for "community" is 0.492 (95% confidence interval from bootstrapped models: 0.471-0.560). This is substantially below the average distance of 0.672, implying that by this semantic measure community changes less than the typical word. Subjectively, these distance values seem quite high in general -- in a [previous experiment](https://ccgilroy.com/community-discourse/historical-change.html#self-similarity) using historical word embeddings from @hamilton_diachronic_2016 to replicate the work of @kulkarni_statistically_2015, I found that the word "community" shifts by a distance of only 0.403 from 1900 to 1990. By comparison, the word "gay," which undergoes a strong shift in meaning, changes by a distance of 0.822 over the course of the same century. The GloVe and soc.motss corpora are from similar time periods, so I surmise that these differences arise from distinct linguistic styles -- formal newswire and Wikipedia articles versus less formal social text [@mcculloch_because_2019]. (Different model architectures are another possibility.)

- @fig-shift shows what is in some sense an intermediate measure -- it is also a cosine distance, but of within-model cosine similarities to a given focal word, of the local neighborhood of words around that word. @hamilton_cultural_2016 develop this "cultural shift" measure on the premise that these neighbors are semantically relevant in a way that more distance words (which were included in the first correlation measure) are not.On this metric, "community" shows a slightly above average shift of 0.303 (95% confidence interval from bootstrapped models: 0.177-0.396, median cultural shift for all words = 0.264). The wide bootstrapped interval, however, implies that this is the least stable of all three measures. 

Taken together, these measures show that "community" changes in meaning to some degree between the generic GloVe model and the local soc.motss corpus, but they offer no definitive conclusion on the comparative magnitude of that change.

<!-- ::: {#fig-metrics layout-ncol=1} -->

![Correlation (between the two models) of (within-model) cosine similarities for every word and all other words.](img/discourse/overall_vocab_correlation.png){#fig-correlation width=50%}

![Between-model cosine distances for every word ("linguistic drift", @hamilton_cultural_2016).](img/discourse/overall_vocab_linguistic_drift.png){#fig-drift width=50%}

![Nearest-neighbor distances, k = 25 neighbors ("cultural shift", @hamilton_cultural_2016).](img/discourse/overall_vocab_cultural_shift.png){#fig-shift width=50%}

<!-- Three vocabulary-wide measures of model stability and semantic change. Values for "community" in the distributions are labeled and marked in red.
::: -->

The next logical question, then, is _how_ does the meaning of community in the context of soc.motss differ from the generic context, and how does it remain similar? Using the semantic dimensions I derived from the GloVe model in the previous section, alongside the additional identity-related dimension I curated based on the soc.motss corpus and model, I investigate what changes and why between the two different embeddings for "community." Because these averaged semantic vectors are intrinsically more likely to be closer to the "community" vector derived from the same model, I re-create each of them from the other model's embedding matrix, and I show both sets for consistency. The soc.motss model matrix is aligned to the GloVe model matrix, as are the 40 bootstrapped models for a 95% confidence interval (although the values from the true corpus are in at one case systematically higher than the bootstrapped values). In total, I make 12 comparisons (3 comparison vectors x 2 source models for those vectors x 2 source models for the "community" vector), shown in @fig-semantic.

This key figure shows how "community" in the context of soc.motss de-emphasizes geography but foregrounds identity instead. At the same time, it retains the Gemeinschaft connotations of community. 

- When the averaged vector of geographic words is derived from the GloVe model, the gap in cosine similarities is the largest among any of the comparisons: the soc.motss embedding for "community" has a cosine similarity with the geography vector of only 0.165 (0.108-0.185), compared to 0.594 for the GloVe "community" embedding. The gap narrows to essentially 0 when the geography vector is re-derived from the same 10 words in the soc.motss model, with a similarity of 0.398 (0.374-0.437) for "community" in soc.motss vs 0.404 for "community" in GloVe -- but the following two semantic dimensions have wider gaps in the opposite direction when constructed in this way. 
- The Gemeinschaft vector in the GloVe model is almost identical to the geography vector in its similarity to the GloVe embedding for "community" (0.586), but its similarity to the soc.motss "community" embedding increases to 0.398 (0.374-0.437) -- still lower, but a narrower gap. Recreated with the same words from the soc.motss vectors, the similarities flip: the similarity to "community" from GloVe is 0.386 (almost the same as the comparable geography vector), but the similarity to soc.motss "community" is now higher, at 0.508 (0.440-0.511). 
- The averaged vector for LGBTQ identity-related words is unambiguously more similar to "community" in soc.motss than in the GloVe model, no matter which model's word vectors are used to derive it. The cosine similarities to the soc.motss "community" embedding are 0.497 (0.429-0.485) when derived from the GloVe model and 0.627 (0.585-0.641) from the soc.motss model (the highest within both sets of comparisons). These compare to similarities of only 0.367 and 0.333 for the GloVe "community" embedding respectively (the lowest in both sets of comparisons).

This approach offers clear, stable rankings and comparisons, showing that "community" in the generic sense is equally similar to both geography and Gemeinschaft, and less so to identity, while "community" as used in soc.motss carries stronger connotations of identity, roughly comparable connotations of Gemeinschaft, and weaker connotations of geography.

<!-- ::: {#fig-comparison layout-ncol=1} -->

!["Community" embeddings from GloVe (Wikipedia 2014 + Gigaword 5) model and word2vec soc.motss (Usenet) model compared to semantic dimension vectors based on averages of 10 words.](img/discourse/motss_semantic_similarity_comparison.png){#fig-semantic width=95%}

!["Community" embeddings from GloVe (Wikipedia 2014 + Gigaword 5) model and word2vec soc.motss (Usenet) model compared to orthogonal projections of GloVe "community" embedding away from semantic dimensions.](img/discourse/motss_orthogonal_comparison.png){#fig-orthogonal width=75%}

<!-- Semantic change in the meaning of "community" between GloVe and soc.motss models, based on three semantic dimensions.
::: -->

To bring everything together and confirm that result, the final piece involves applying the orthogonal projections from the end of the previous section. These come from the GloVe model alone, and I compare them to the "community" embeddings from both models in @fig-orthogonal. For reference, I also compare the two "community" embeddings themselves in the third row of the figure. As shown above, both orthogonal projections of the GloVe "community" embedding -- away from the Gemeinschaft words and away from the geography words -- retain high cosine similarities to the original vector, 0.810 and 0.804 respectively. This is not the case for the soc.motss "community" embedding, which is markedly less similar to community-without-Gemeinschaft (or, community-as-geography), with a similarity of 0.374 (0294-0.393). By contrast, it remains equally similar to community-without-geography (or, community-as-Gemeinschaft) as it is to the GloVe "community" embedding overall, with similarities of 0.510 (0.451-0.523) and 0.508 (0.440-0.529) respectively. This is a different way of looking at the problem of semantic similarity and semantic change, and it has implications for using GloVe vectors as a measurement tool that I will explore in the next chapter.

## Discussion

The structure of meaning around "community" in the generic GloVe embeddings shows, mathematically, how the word bundles and links together two sets of connotations: on the one hand spatial or geographic, and on the other hand social or _gemeinschaftlich_. This dual structure might appear intuitive, but it wasn't predictable in advance. 

At the same time, this structure doesn't fully carry over into the local context of an LGBTQ virtual community. In soc.motss, the meaning of community is not totally alien or unrecognizable from the generic meaning (and why would it be?), but it is clearly distinct. Across both contexts, the sociological element of community is present in everyday usage. In the soc.motss corpus, "community" retains the _Gemeinschaft_ connotations of social organization and groupness, but incorporates markedly less of the geographic or spatial connotations of community. Instead, it substitutes language related to LGBTQ identities. This case is notable in part because it comes from a time period where groups like soc.motss were proving that virtual community was in fact possible [@rheingold_virtual_2000], and it affirms the presence and visibility of LGBTQ community to that process.

Potential limitations of this work relate to robustness, scope, and generalization. While I am convinced that the findings I present here are robust, a key limitation of any text analysis work centers around corpus and model quality. It would be possible to do even more to evaluate the stability and viability of the locally-trained embeddings [see @antoniak_evaluating_2018-1], or to incorporate corpora from additional groups -- although there is little evidence from prior work to expect that the results would differ dramatically [@dame-griff_herding_2019]. This work also demonstrates that there is some payoff to closely interrogating the embedding representation of a single word, provided that the associated concept has enough theoretical and empirical complexity to warrant a close read. The downside, then, is that generalizing to other complex concepts is inherently slow and requires interpretative work.

This chapter analyzed the meaning of "community" at a discursive and cultural level. While I qualitatively contextualized the social environment of Usenet and the soc.motss newsgroup, I didn't explicitly connect any social characteristics to discourse about "community." In the following chapter, I will attempt to characterize the structural, relational, and interactional characteristics of group conversations that invoke the idea of community.

## Acknowledgments

I thank Avery Dame-Griff for sharing code, advice, and encouragement for working with Usenet archives, and Steve Goodreau for the initial suggestion to look more closely at soc.motss in particular. Previous versions of this chapter received generous feedback from the Community Data Science Collective and the Metaphors and Meaning roundtable at ASA 2021.
